{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# NEURAL NETWORKS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Artificial Neuron\n",
    "\n",
    "*An artificial neuron is made up of the following*\n",
    "- *Input Nodes*\n",
    "- *Weights*\n",
    "- *Activation Function*\n",
    "- *Output Node*\n",
    "\n",
    "<br>\n",
    "\n",
    "*Every input node of an artificial neuron has a weight attached to it which scales the input at the input node*\n",
    "\n",
    "<br>\n",
    "\n",
    "*An artificial neuron via its weights and input nodes computes a weighted sum of the inputs present at the input nodes. This weighted sum is then applied to an activation function $f$, which can be linear or non-linear. The result of the activation function on the weighted sum produces the output at the output node*\n",
    "*Mathematically an artificial neuron carries out the operation:*\n",
    "$$ y = f(\\sum^m_{i=1}\\, w_{i}x_{i}) $$\n",
    "$$ x_{i}: input\\ at\\ input\\ node\\ i $$\n",
    "$$ w_{i}: weight\\ for\\ input\\ node\\ i$$\n",
    "$$ f: activation\\ function\\ $$\n",
    "$$ y: output\\ at\\ output\\ node $$\n",
    "\n",
    "*An artificial neuron can be linear or non-linear depending on the nature of the activation function being used, an example linear activation function is a scaling function and an example non-linear function is the sigmoid function to be discussed in the next module*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling A Linear Discrete Time (Dynamic) System Using A Linear Neuron\n",
    "In what follows, we will motivate a number of important concepts related to the gradient descent method using an illustrative problem.\n",
    "\n",
    "Lets assume we are given a set of data $\\{u_k,y_k\\}$. That is, a dataset with two columns. One column could be time, and the other, temperature. Perhaps, the first could be a variable that affects the stock price of Tesla, while the other is the stock price itself. In other words, the two columns might represent any two variables that are related. We intend to find that relationship using system identification.\n",
    "\n",
    "A very critical first step is to determine a model structure that might accrately model the data. This usually requires some knowledge about the system, or a similar system. Such a knowledge allows us to predict a GENERAL form for the model.\n",
    "\n",
    "Suppose that, for our sample problem, we have reason to believe that it can be modelled as a linear, discrete time dynamic system described by:\n",
    "$$ y(k) = a_{1}\\,y(k-1) + a_{2}\\,y(k-2) + b_{1}\\,u(k-1)$$ \n",
    "\n",
    "*A linear neuron having three input nodes can model the systems behaviour by assigning weights of the neuron as coefficients of the system and corresponding neuron input nodes as corresponding independent variables of the system This is done by making:*\n",
    "$$ w_{1} = b_{1} $$\n",
    "$$ w_{2} = a_{1} $$\n",
    "$$ w_{3} = a_{2} $$\n",
    "$$ x_{1} = u(k-1) $$\n",
    "$$ x_{2} = y(k-1) $$\n",
    "$$ x_{3} = y(k-2) $$\n",
    "\n",
    "*Given that we have example inputs and output from the linear discrete dynamic system, how do we make sure that the linear neuron, for a set of example inputs produces an output close to the corresponding example output*\n",
    "\n",
    "*The inputs to the linear neuron cannot be altered, but the corresponding outputs can be altered by altering the weights of the linear neuron. So the question is how do we change the weights such that the output of the linear neuron is close to the actual example output as much as possible. We are basically saying how can the linear neuron learn the best weight values that fits the example behaviour of the discrete dynamic system*\n",
    "\n",
    "*Generally methods for a linear neuron to learn these weights are called weight update rules or learning rules. The most common of these rules which will be used during this course is called the gradient descent rule, we discuss the gradient descent rule, but first let us generate an example(training) data from a discrete dynamic system  we intend to model using a linear neuron*\n",
    "\n",
    "*First, we are going to generate a dataset. We will do so deterministically, so that we can determine at the end of the Lab whether our model is correct. Mote that in real life, even though YOU will usually not generate the data analytically (rather, obtaining them experimentally, or from a third party), there would nonetheless be an underlying relationship. The only difference is that in this case, we wish to generate the data analytically so we can see how well the gradient descent algorithm performs.\n",
    "\n",
    "***TODO: Run the cell below to generate the dataset on which we wish to carry out system identification:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T19:46:02.608661Z",
     "start_time": "2023-04-07T19:46:02.583739Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights b1, a1, a2, b1 are: 0.21, 0.15, 0.38.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input(u)</th>\n",
       "      <th>Output(y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.128100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.067515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.201605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.168957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.193505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.097429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.249846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.135400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Input(u)  Output(y)\n",
       "0        0.57   0.000000\n",
       "1        0.61   0.000000\n",
       "2        0.23   0.128100\n",
       "3        0.68   0.067515\n",
       "4        0.58   0.201605\n",
       "..        ...        ...\n",
       "995      0.46   0.168957\n",
       "996      0.02   0.193505\n",
       "997      0.77   0.097429\n",
       "998      0.29   0.249846\n",
       "999      0.14   0.135400\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "number_of_samples = 1000\n",
    "#np.random.seed(40)\n",
    "#random.seed(40)\n",
    "\n",
    "# generate the coefficients of the real system randomly\n",
    "#b1, a1, a2 = np.random.uniform(0.1, 0.4, size=3)\n",
    "#b1, a1, a2 = round(b1, 2), round(a1, 2), round(a2, 2)  # round to 2 decimal places\n",
    "\n",
    "b1, a1, a2 = 0.21, 0.15, 0.38\n",
    "\n",
    "\n",
    "# generate the input column\n",
    "u = np.random.rand(number_of_samples)\n",
    "u = np.round(u, decimals=2)\n",
    "\n",
    "# create and populate Y\n",
    "y = np.zeros(number_of_samples)\n",
    "for k in range(2,number_of_samples):\n",
    "    y[k] = a2 * y[k-2] + a1*y[k-1] + b1* u[k-1]\n",
    "\n",
    "supplied_dataset = pd.DataFrame({'Input(u)': u, 'Output(y)': y})\n",
    "\n",
    "# display the weights and the dataset\n",
    "print(f'Weights b1, a1, a2, b1 are: {b1}, {a1}, {a2}.')\n",
    "supplied_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, we have a dataset, which in real life, would have been the starting point of this system identification assignment. Carefully note the weights that were used to generate this dataset. They are the \"true\" underlying dynamics of the system (which, to stress again, you would generally NOT know in real life).\n",
    "\n",
    "Given this dataset, you somehow guessed that it could be modelled as $ y(k) = a_{1}\\,y(k-1) + a_{2}\\,y(k-2) + b_{1}\\,u(k-1)$. We now want to see how to use gradient descent to determine the values of the weight.\n",
    "\n",
    "***TODO: Run the cell below to generate a re-organize the training data:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T19:46:04.990007Z",
     "start_time": "2023-04-07T19:46:04.975006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u(k-1)</th>\n",
       "      <th>y(k-1)</th>\n",
       "      <th>y(k-2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.128100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.067515</td>\n",
       "      <td>0.128100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.188319</td>\n",
       "      <td>0.105023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.168957</td>\n",
       "      <td>0.188319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.193505</td>\n",
       "      <td>0.168957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.097429</td>\n",
       "      <td>0.193505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.249846</td>\n",
       "      <td>0.097429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     u(k-1)    y(k-1)    y(k-2)\n",
       "0      0.00  0.000000  0.000000\n",
       "1      0.57  0.000000  0.000000\n",
       "2      0.61  0.000000  0.000000\n",
       "3      0.23  0.128100  0.000000\n",
       "4      0.68  0.067515  0.128100\n",
       "..      ...       ...       ...\n",
       "995    0.48  0.188319  0.105023\n",
       "996    0.46  0.168957  0.188319\n",
       "997    0.02  0.193505  0.168957\n",
       "998    0.77  0.097429  0.193505\n",
       "999    0.29  0.249846  0.097429\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate examples(training data)\n",
    "\n",
    "# our dataset has just two columns (one 'input', one 'output'), but the neuron model we want to use has three inputs and one output. We need to re-structure the data for easy computations.\n",
    "\n",
    "\n",
    "#N = 1000\n",
    "x = np.zeros((3,number_of_samples))\n",
    "#X[0,0] = random.random() #u\n",
    "#X[1,0] = random.random() #y(k-1)\n",
    "#X[2,0] = random.random() #y(k-2)\n",
    "\n",
    "for n in range(number_of_samples-1):\n",
    "    #X[3,n] = y[n] #y(k)\n",
    "    x[0,n+1] = u[n]     #u(k-1)\n",
    "    x[1,n+1] = y[n]     #y(k-1)\n",
    "    if(n<number_of_samples-2):\n",
    "        x[2,n+2] = y[n]  #y(k-2)\n",
    "\n",
    "\n",
    "inputs = pd.DataFrame(x.T,columns=[\"u(k-1)\",\"y(k-1)\",\"y(k-2)\"])\n",
    "outputs = pd.DataFrame(y, columns=[\"y\"])\n",
    "\n",
    "inputs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations and Symbols\n",
    "\n",
    "$ y(k):$ actual output from system at timestep k\n",
    "\n",
    "$ y^{pred}(k):$ output computed by the neuron at timestep k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function\n",
    "\n",
    "*Since we are trying to alter the weights of the linear neuron such that $y^{pred}(k)$ is as close to $y(k)$ as possible, then based on the distance:*\n",
    "$$y(k)-y^{pred}(k)$$\n",
    "*we should be able to determine in what manner and to what extent we should alter the weights of the neuron.*\n",
    "\n",
    "*There should be a measure of this distance which depends on the weights of the neuron. This measure of distance is called the cost function and is defined as:*\n",
    "$$ E = \\frac{1}{2}\\sum^{N-1}_{k=0}\\,e_{k} = \\frac{1}{2}\\sum^{N-1}_{k=0}\\,(y(k)-y^{pred}(k))^2 $$\n",
    "\n",
    "*where:*\n",
    "$$ e_{k} = (y(k)-y^{pred}(k))^2 : error\\ for\\ each\\ example $$\n",
    "$$ E: Average\\ error\\ on\\ all\\ examples $$\n",
    "\n",
    "*Cost function $E$ depends on the weights through $y^p(k)$ which is computed as:*\n",
    "$$ y^{pred}(k) = \\sum^m_{i=1}\\,w_{i}x_{i}(k) $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Rule\n",
    "\n",
    "*Gradient descent acts to arrive at the optimal weight values by measuring the changes in the cost function value $E$ due to changes in the weights. This is done through the gradients:*\n",
    "$$ \\frac{\\partial{E}}{\\partial{w_{i}}} ; i=1,2,.....,m $$\n",
    "\n",
    "*Then from these gradients the manner in which each weight should be altered is determined*\n",
    "\n",
    "#### Form of the weight update rule\n",
    "\n",
    "*A positive gradient indicates that the weight should be reduced to reduce the cost function and a negative gradient indicates that the weight should increased to reduce the cost function, thus the form of the weight update rule that achieves this. For each weight:*\n",
    "$$ w^{new}_{i} = w^{old}_{i} - \\eta\\frac{\\partial{E}}{\\partial{w_{i}}} $$\n",
    "$$ \\eta: learning\\ rate $$\n",
    "\n",
    "*The learning rate determines by what amount the weight is increased or reduced accordingly*\n",
    "\n",
    "#### Computing the gradient\n",
    "\n",
    "*How do we compute the gradient $\\frac{\\partial{E}}{\\partial{w_{i}}}$*\n",
    "$$ E = \\frac{1}{2}\\sum^{N-1}_{k=0}\\,e_{k} = \\frac{1}{2}\\sum^{N-1}_{k=0}\\,(y(k)-y^{pred}(k))^2 \\\\$$\n",
    "$$ y^{pred}(k) = \\sum^m_{i=1}\\,w_{i}x_{i}(k) \\\\$$\n",
    "$$ \\therefore \\frac{\\partial{E}}{\\partial{w_{i}}} = \\frac{\\partial{E}}{\\partial{y^p}} * \\frac{\\partial{y^p}}{\\partial{w_{i}}} \\hspace{0.5in} i=1,......,m $$\n",
    "\n",
    "*We can thus find the gradients to be:*\n",
    "$$ \\frac{\\partial{E}}{\\partial{y^p}} = -\\sum^{N-1}_{k}\\,y(k)-y^{pred}(k) \\hspace{0.5 in} and $$\n",
    "$$ \\frac{\\partial{y^p}}{\\partial{w_{i}}} = x_{i}(k) $$\n",
    "$$ \\therefore \\frac{\\partial{E}}{\\partial{w_{i}}} = -\\sum^{N-1}_{k}\\,(y(k)-y^{pred}(k))x_{i}(k) $$\n",
    "\n",
    "*We can say that*\n",
    "$$ \\delta(k) = (y(k)-y^{pred}(k)) $$\n",
    "$$ \\therefore \\frac{\\partial{E}}{\\partial{w_{i}}} = -\\sum^{N-1}_{k}\\,\\delta(k)x_{i}(k) $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting The Neuron Weights\n",
    "\n",
    "*Now that we have the cost function, weights and gradient of the cost function with respect to the weights, how do we use all of this to fit neuron weights*\n",
    "\n",
    "*There are two ways to this, one is called the instantaneous leaning and the other is called batch learning or update.*\n",
    "\n",
    "*What we have described so far implements batch update(learning). Let us explain how to implement this*\n",
    "\n",
    "#### Batch update(learning)\n",
    "1. *Initialize your weights to random values between 0 and 1.*\n",
    "2. *Compute the outputs $y^{pred}(k)$ for all examples $k$.*\n",
    "3. *Compute the gradient of the cost function with respect to each weight $\\frac{\\partial{E}}{\\partial{w_{i}}} (i=1,...,m)$  from all $y^{pred}(k), y(k)\\ and\\ w_{i}$.*\n",
    "4. *Update each weight from its old value and cost function gradient using the weight update rule*\n",
    "5. *Recompute the outputs $y^{pred}(k)$ for all examples $k$ and evaluate the cost function $E$ from all $y^{pred}(k)\\ and\\ y(k)$*\n",
    "6. *Go through steps 2 to 5 again until certain pre-defined iteration steps is complete or until the cost function $E$ is at its minimum and no longer changing*\n",
    "\n",
    "*Let us implement this batch update and try it out on our example training data generated previously*\n",
    "\n",
    "*We use the mean squared error from scikit learn as a means to verify that the direction of the cost function is valid, the mean squared error is a valid measure of cost*\n",
    "\n",
    "*Try writing the instantaneous update method algorithm in python and matlab on your own*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T19:46:18.013795Z",
     "start_time": "2023-04-07T19:46:14.437448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10 %\n",
      "Progress: 20 %\n",
      "Progress: 30 %\n",
      "Progress: 40 %\n",
      "Progress: 50 %\n",
      "Progress: 60 %\n",
      "Progress: 70 %\n",
      "Progress: 80 %\n",
      "Progress: 90 %\n",
      "Progress: 100 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors at last iteration:[-3.01681953e-05  3.41778282e-03 -3.35388842e-03]\n",
      "Weights obtained by System Identification:[0.21 0.15 0.38]\n",
      "Remember, the real system coefficients b1, a1, a2, b1 are: 0.21, 0.15, 0.38.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "w = [0.1,0.6, 0.9]\n",
    "#w = np.random.randn(3)\n",
    "eta = 0.001\n",
    "number_of_iterations = 1000\n",
    "ypred = np.zeros(number_of_samples)\n",
    "error_series = []\n",
    "progress_counter = 0\n",
    "\n",
    "\n",
    "history = {\n",
    "    'E':[],\n",
    "    'weights':[]\n",
    "}\n",
    "\n",
    "\n",
    "for q in range(number_of_iterations):\n",
    "    gradient_per_iteration = np.zeros(3)\n",
    "    local_error = [0,0,0]           # initialize the error for this entire iteration through the whole dataset\n",
    "\n",
    "    for k in range(2, number_of_samples):                       # run through the whole dataset for this iteration, q\n",
    "        ypred[k] = w[0]*x[0, k] + w[1]*x[1,k] + w[2]*x[2, k]    # predict a value for this particular kth value of the various inputs\n",
    "        for i in range(3):\n",
    "            #local_error[i] = (y[k]-ypred[k])*x[i, k]            # the local gradient for the ith input\n",
    "            gradient_per_iteration[i] = gradient_per_iteration[i] + (y[k]-ypred[k])*x[i, k]\n",
    "\n",
    "    for i in range(3):\n",
    "        w[i] = w[i] + (gradient_per_iteration[i]*eta)\n",
    "\n",
    "\n",
    "    # record data for plotting after everything\n",
    "    error_series.append([gradient_per_iteration[0], gradient_per_iteration[1], gradient_per_iteration[2]])\n",
    "    history['E'].append(gradient_per_iteration)\n",
    "    history['weights'].append(w)\n",
    "\n",
    "    # this block is just to allow a progress report\n",
    "    if q%(number_of_iterations/10)==0:\n",
    "        progress_counter+=10\n",
    "        print(f'Progress: {progress_counter} %')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history['weights'] = np.array(history['weights'])\n",
    "history['E'] = np.array(history['E'])\n",
    "plt.plot(error_series)#, error_sum[1], error_sum[2])\n",
    "plt.ylim(-0.25, 0.25)\n",
    "plt.legend(['w1', 'w2','w3'])\n",
    "plt.show()\n",
    "\n",
    "print(\"Errors at last iteration:\"+str(gradient_per_iteration))\n",
    "print(\"Weights obtained by System Identification:\"+str(np.round(w, decimals=2)))\n",
    "print(f'Remember, the real system coefficients b1, a1, a2, b1 are: {b1}, {a1}, {a2}.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### DIY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "1. Modify the eta in the code above to 0.1, while leaving the number of iterations as 1000.\n",
    "    Q: what do you observe? What do you think is responsible for this?\n",
    "2. Modify the eta, using 0.00001 instead now. Leave the number of iterations at 1000. Run the code again, noting how fast the weights drop\n",
    "3. Finally leave the eta at 0.00001, and increase the number of iterations to 10000. What are your observations?\n",
    "    Q: from the above, what can you conclude about using an excessively high $\\eta$ ?\n",
    "    Q: what do you think prevents us from just using arbitrarily high number of iterations?\n",
    "    Q: Can you think  of a way to achieve the highest possible value of $\\eta$ and the lowest number of iterations that would converge rapidly to the right weights?\n",
    "4. The above code starts with random weights. There is a commented-out line that allows you to start with specified values. Play with that, and observe the effect. Stay between 0 and 1. Try something out of that range, and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Stochastic Gradient Descent\n",
    "In updating weights, the last gradient descent code used the entire dataset to compute the gradient.\n",
    "There is a slightly different version in which the weights are updated more rapidly, as explaied in the slides. As an assignment, modify the code, to update the weights more rapidly as discussed in the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## To modify\n",
    "\n",
    "\n",
    "w = [0.1,0.6, 0.9]\n",
    "#w = np.random.randn(3)\n",
    "eta = 0.001\n",
    "number_of_iterations = 1000\n",
    "ypred = np.zeros(number_of_samples)\n",
    "error_series = []\n",
    "progress_counter = 0\n",
    "\n",
    "\n",
    "history = {\n",
    "    'E':[],\n",
    "    'weights':[]\n",
    "}\n",
    "\n",
    "\n",
    "for q in range(number_of_iterations):\n",
    "    gradient_per_iteration = np.zeros(3)\n",
    "    local_error = [0,0,0]           # initialize the error for this entire iteration through the whole dataset\n",
    "\n",
    "    for k in range(2, number_of_samples):                       # run through the whole dataset for this iteration, q\n",
    "        ypred[k] = w[0]*x[0, k] + w[1]*x[1,k] + w[2]*x[2, k]    # predict a value for this particular kth value of the various inputs\n",
    "        for i in range(3):\n",
    "            #local_error[i] = (y[k]-ypred[k])*x[i, k]            # the local gradient for the ith input\n",
    "            gradient_per_iteration[i] = gradient_per_iteration[i] + (y[k]-ypred[k])*x[i, k]\n",
    "\n",
    "    for i in range(3):\n",
    "        w[i] = w[i] + (gradient_per_iteration[i]*eta)\n",
    "\n",
    "\n",
    "    # record data for plotting after everything\n",
    "    error_series.append([gradient_per_iteration[0], gradient_per_iteration[1], gradient_per_iteration[2]])\n",
    "    history['E'].append(gradient_per_iteration)\n",
    "    history['weights'].append(w)\n",
    "\n",
    "    # this block is just to allow a progress report\n",
    "    if q%(number_of_iterations/10)==0:\n",
    "        progress_counter+=10\n",
    "        print(f'Progress: {progress_counter} %')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history['weights'] = np.array(history['weights'])\n",
    "history['E'] = np.array(history['E'])\n",
    "plt.plot(error_series)#, error_sum[1], error_sum[2])\n",
    "plt.ylim(-0.25, 0.25)\n",
    "plt.legend(['w1', 'w2','w3'])\n",
    "plt.show()\n",
    "\n",
    "print(\"Errors at last iteration:\"+str(gradient_per_iteration))\n",
    "print(\"Weights obtained by System Identification:\"+str(np.round(w, decimals=2)))\n",
    "print(f'Remember, the real system coefficients b1, a1, a2, b1 are: {b1}, {a1}, {a2}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
